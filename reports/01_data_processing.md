# 01 â€“ Veri Ä°ÅŸleme ve Temizlik SÃ¼reci (Data Processing Report)

Bu rapor, Introduction to Data Science projesi kapsamÄ±nda kullanÄ±lan iki farklÄ± maaÅŸ veri setinin (Salary Data ve Salary by Job Title and Country) sistematik biÃ§imde birleÅŸtirilmesi, temizlenmesi, normalleÅŸtirilmesi ve modellemeye hazÄ±r hale getirilmesi iÃ§in uygulanan tÃ¼m yÃ¶ntemleri ayrÄ±ntÄ±lÄ± ÅŸekilde aÃ§Ä±klamaktadÄ±r. SÃ¼reÃ§ boyunca Python, Pandas ve veri Ã¶n iÅŸleme teknikleri kullanÄ±lmÄ±ÅŸ, tÃ¼m adÄ±mlar notebook ortamÄ±nda tekrarlanabilir bir pipeline hÃ¢line getirilmiÅŸtir.

AmaÃ§, farklÄ± kaynaklardan gelen verileri tutarlÄ±, eksiksiz, duplicate iÃ§ermeyen, uÃ§ deÄŸerlerden arÄ±ndÄ±rÄ±lmÄ±ÅŸ ve istatistiksel olarak gÃ¼venilir tek bir ana veri setine dÃ¶nÃ¼ÅŸtÃ¼rmektir. Nihai veri seti `data/processed/main_salary_dataset.csv` olarak kaydedilmiÅŸtir.

---

# ğŸ“Œ Veri Ä°ÅŸleme AdÄ±mlarÄ±nÄ±n AyrÄ±ntÄ±lÄ± AÃ§Ä±klamasÄ± (TÃ¼rkÃ§e)

---

## 1. Veri Setlerinin SeÃ§ilmesi, YÃ¼klenmesi ve Ä°lk Ä°ncelemesi

Ä°ki farklÄ± Kaggle veri seti kullanÄ±ldÄ±:

1. **salary_data.csv**  
2. **salary_by_jobtitle_country.csv**

Her iki veri seti de yaÅŸ, eÄŸitim seviyesi, iÅŸ unvanÄ±, deneyim sÃ¼resi ve maaÅŸ gibi modelde kullanacaÄŸÄ±mÄ±z ortak Ã§ekirdek Ã¶zellikleri iÃ§eriyordu. Pandas ile dosyalar okunarak:

- toplam satÄ±r sayÄ±larÄ±,
- kolon isimleri,
- veri tipleri,
- eksik deÄŸerlerin daÄŸÄ±lÄ±mÄ±,
- kategorik deÄŸer Ã§eÅŸitliliÄŸi

incelenmiÅŸtir.

Bu inceleme, kolon isimlerindeki uyumsuzluklarÄ±, farklÄ± formatlarÄ± ve eksik veri yapÄ±larÄ±nÄ± tespit etmemizi saÄŸlamÄ±ÅŸtÄ±r.

---

## 2. Ortak ÅemanÄ±n OluÅŸturulmasÄ±

Verilerin iki kaynaktan geliyor olmasÄ± kolon adlarÄ±nÄ± standartlaÅŸtÄ±rmayÄ± gerektirmiÅŸtir. Modelleme aÅŸamasÄ±nda Python fonksiyonlarÄ±yla uyumlu olmasÄ± iÃ§in bir â€œuniform schemaâ€ belirledik.

Uygulanan dÃ¶nÃ¼ÅŸÃ¼mler:

- Age â†’ age  
- Job Title â†’ job_title  
- Education Level â†’ education_level  
- Years of Experience â†’ years_experience  
- Salary â†’ salary  

AyrÄ±ca tÃ¼m veri setlerinde bulunmayan bir field olan **seniority_level** (kÄ±dem seviyesi) kolonunu veri yapÄ±sÄ±na ekledik ve sonraki adÄ±mlarda bu deÄŸeri hesapladÄ±k.

Bu adÄ±m sayesinde iki veri seti aynÄ± kolon yapÄ±sÄ±na sahip olmuÅŸ, birleÅŸmeye hazÄ±r hÃ¢le gelmiÅŸtir.

---

## 3. Seniority Bilgisinin TekilleÅŸtirilmesi ve TutarlÄ± Bir KÄ±deme DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi

KÄ±dem bilgisi veri setlerinde tutarlÄ± bir ÅŸekilde sunulmuyordu:

- Bir veri setinde `Senior` adÄ±yla 0/1 formatÄ±nda bulunuyordu.
- DiÄŸer veri setinde iÅŸ unvanÄ± iÃ§erisinde â€œSenior â€¦â€ veya â€œJunior â€¦â€ ÅŸeklinde geÃ§iyordu.
- BazÄ± kayÄ±tlarda kÄ±dem bilgisi hiÃ§ belirtilmemiÅŸti.

Bu nedenle veri bilimsel bir karar mekanizmasÄ± oluÅŸturduk:

### KullanÄ±lan YÃ¶ntemler:
- Text mining: job_title iÃ§inde kelime arama  
- Boolean mapping: Senior kolonundan ikili mapping  
- Median salary karÅŸÄ±laÅŸtÄ±rmasÄ±: Neutral kayÄ±tlarÄ±n maaÅŸ seviyesine bakarak kÄ±dem sÄ±nÄ±fÄ± tahmini  

### Kural Seti:
- Senior = 1 â†’ **senior**
- job_title iÃ§inde â€œseniorâ€ geÃ§iyorsa â†’ **senior**
- job_title iÃ§inde â€œjuniorâ€ geÃ§iyorsa â†’ **junior**
- Bilgi yoksa â†’ **junior**

Bu seÃ§imin doÄŸruluÄŸu median maaÅŸ analiziyle teyit edildi:

| Seviye | Median maaÅŸ |
|--------|-------------|
| Junior | 100,000 |
| Neutral (seviye belirtilmemiÅŸ) | 110,000 |
| Senior | 140,000 |

Neutral median maaÅŸÄ±nÄ±n juniorâ€™a yakÄ±n olmasÄ± nedeniyle bu grubun â€œjuniorâ€ olarak etiketlenmesi **istatistiksel olarak en doÄŸru karar**dÄ±r.

---

## 4. Job Title Temizleme, Normalizasyon ve Anlamsal BirleÅŸtirme

Data Quality Report aÅŸamasÄ±nda iÅŸ unvanlarÄ±nda:

- yazÄ±m hatalarÄ± (Ã¶r. â€œjuniourâ€),
- varyasyonlar (Ã¶r. â€œback end developerâ€ vs â€œbackend developerâ€),
- anlamca aynÄ± fakat farklÄ± yazÄ±lmÄ±ÅŸ pozisyonlar,
- eksik veya yanlÄ±ÅŸ giriÅŸler,

tespit edilmiÅŸtir.

Bu nedenle geliÅŸmiÅŸ bir â€œjob title normalization pipelineâ€ geliÅŸtirilmiÅŸtir.

### Uygulanan Temizlik AdÄ±mlarÄ±:
#### **A) YazÄ±m hatasÄ± dÃ¼zeltme (typo correction)**
Ã–rnekler:
- â€œjuniour hr coordinatorâ€ â†’ â€œjunior hr coordinatorâ€
- â€œsocial media manâ€ â†’ â€œsocial media managerâ€

#### **B) VaryasyonlarÄ± tekilleÅŸtirme**
- â€œcustomer service repâ€ â†’ â€œcustomer service representativeâ€
- â€œfront end developerâ€ â†’ â€œfrontend developerâ€
- â€œback end developerâ€ â†’ â€œbackend developerâ€
- â€œfull stack engineerâ€ â†’ â€œfullstack engineerâ€

#### **C) AnlamdaÅŸ pozisyon birleÅŸtirmeleri**
- â€œdeveloperâ€ â†’ â€œsoftware developerâ€
- â€œscientistâ€ â†’ â€œresearch scientistâ€
- â€œit project managerâ€ â†’ â€œproject managerâ€

Bu iÅŸlemler sonucunda benzersiz unvan sayÄ±sÄ± **125 â†’ 118**â€™e dÃ¼ÅŸmÃ¼ÅŸ, veri Ã§ok daha tutarlÄ± hÃ¢le gelmiÅŸtir.

---

## 5. Education Level Normalizasyonu

Veri setlerindeki eÄŸitim seviyeleri farklÄ± formatlarda olduÄŸundan tek bir standarda Ã§evrilmiÅŸtir:

high_school, bachelor, master, phd, unknown


Eksik deÄŸerler `"unknown"` etiketiyle doldurulmuÅŸtur.

---

## 6. SayÄ±sal KolonlarÄ±n Temizlenmesi ve TÃ¼r DÃ¶nÃ¼ÅŸÃ¼mleri

age, years_experience ve salary kolonlarÄ±nda:

- sayÄ±sal olmayan karakterler temizlenmiÅŸ,
- tÃ¼m deÄŸerler sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ,
- dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemeyenler NaN yapÄ±lmÄ±ÅŸtÄ±r.

Eksik sayÄ±sal deÄŸerler median ile doldurulmuÅŸtur.

Bu adÄ±m veri setindeki istatistiksel tutarlÄ±lÄ±ÄŸÄ± artÄ±rmÄ±ÅŸtÄ±r.

---

## 7. MantÄ±k Kontrolleri ve AykÄ±rÄ± DeÄŸerlerin Filtrelenmesi

AÅŸaÄŸÄ±daki kurallarla mantÄ±k dÄ±ÅŸÄ± kayÄ±tlar Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r:

- age âˆ‰ [18, 70] â†’ silindi
- years_experience âˆ‰ [0, 50] â†’ silindi
- salary â‰¤ 0 â†’ silindi
- salary Ã¼st %1 dilim â†’ **uÃ§ deÄŸer olarak Ã§Ä±karÄ±ldÄ±**  
  (Ham veri 99. persentil: 210,000 â†’ dÃ¼zenlenmiÅŸ: 200,000)

Bu adÄ±m modelde uÃ§ deÄŸerlerin yarattÄ±ÄŸÄ± dengesizlikleri Ã¶nlemek iÃ§in gereklidir.

---

## 8. Eksik DeÄŸer YÃ¶netimi

- Salary eksik olan kayÄ±tlar â†’ tamamen Ã§Ä±karÄ±ldÄ±  
- Kategorik eksikler â†’ â€œunknownâ€  
- SayÄ±sal eksikler â†’ median  

Bu strateji hem bilgi kaybÄ±nÄ± azaltmÄ±ÅŸ hem de modelin stabil Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

## 9. Veri BirleÅŸtirme ve Duplicate TemizliÄŸi

Ä°ki veri seti concat ile birleÅŸtirildi.

Duplicate kontrolÃ¼ ÅŸu kolonlarla yapÄ±ldÄ±:

age, job_title, education_level, years_experience, salary, seniority_level

SonuÃ§lar:

- Duplicate (before): **9991**
- Duplicate (after): **0**

Bu adÄ±m dataset'in gÃ¼venilirliÄŸini bÃ¼yÃ¼k Ã¶lÃ§Ã¼de artÄ±rmÄ±ÅŸtÄ±r.

---

## 10. Nihai Veri Seti ve Kalite Ã–zeti

TemizlenmiÅŸ veri seti kaydedildi:

data/processed/main_salary_dataset.csv

---

# ğŸ“Š Veri Kalitesi ve Ã‡eÅŸitlilik Ã–zeti

### age  
- Benzersiz: 41  
- Ortalama: 35.27  

### job_title  
- Benzersiz: 118  

### education_level  
- bachelor, high_school, master, phd, unknown  

### years_experience  
- Benzersiz: 37  

### salary  
- Benzersiz: 437  
- Ortalama: 112,905  

### seniority_level  
- junior, senior  

---

## ğŸ“ Revizyon Notu

Data Quality Report aÅŸamasÄ±nda tespit edilen job title tutarsÄ±zlÄ±klarÄ± dÃ¼zeltilmiÅŸ; typo correction, string normalization ve semantic merging adÄ±mlarÄ± uygulanarak nihai veri seti tekrar oluÅŸturulmuÅŸtur.

---

# 01 â€“ Data Processing Report (English Version)

This report documents the full preprocessing pipeline applied to the two salary datasets used in the project. All steps were implemented in Python using Pandas, ensuring a reproducible and structured workflow. The goal is to produce a unified, consistent, clean, duplicate-free, and statistically reliable dataset stored as `data/processed/main_salary_dataset.csv`.

---

## ğŸ“Œ Detailed Summary of Data Processing Steps (English)

---

### 1. Dataset Loading and Initial Exploration

Two Kaggle datasets were used:

- salary_data.csv  
- salary_by_jobtitle_country.csv  

We inspected:

- column names and data types  
- missing values  
- categorical distributions  
- sample rows  
- schema differences  

This guided the standardization decisions that followed.

---

## 2. Schema Standardization

Columns were aligned to a unified schema:

- Age â†’ age  
- Job Title â†’ job_title  
- Education Level â†’ education_level  
- Years of Experience â†’ years_experience  
- Salary â†’ salary  

We also introduced a new field, **seniority_level**, to harmonize inconsistent seniority information.

Final schema:

age, job_title, education_level, years_experience, salary, seniority_level


---

## 3. Seniority Harmonization

Seniority appeared in two incompatible formats:

- As a binary field (`Senior = 0/1`)  
- Embedded inside job titles (â€œSenior â€¦â€, â€œJunior â€¦â€)  

We unified this into a single seniority_level field using:

### Methods Applied:
- Keyword scanning in job titles  
- Boolean mapping from Senior column  
- Median salary comparison for neutral records  

### Final Rules:
- Senior = 1 â†’ senior  
- job_title contains â€œseniorâ€ â†’ senior  
- job_title contains â€œjuniorâ€ â†’ junior  
- no seniority info â†’ junior  

Median salary analysis validated this mapping:

| Level | Median Salary |
|-------|---------------|
| Junior | 100,000 |
| Neutral | 110,000 |
| Senior | 140,000 |

Neutral values were statistically closer to junior, so they were labeled as junior.

---

## 4. Job Title Normalization (Advanced Text Cleaning)

The Data Quality Report revealed multiple issues:

- typos  
- inconsistent spacing  
- semantic duplicates  
- incomplete role names  

We implemented a multi-phase normalization pipeline:

### **A) Typo Correction**
- â€œjuniour hr coordinatorâ€ â†’ â€œjunior hr coordinatorâ€
- â€œsocial media manâ€ â†’ â€œsocial media managerâ€

### **B) Variation Merging**
- â€œcustomer service repâ€ â†’ â€œcustomer service representativeâ€
- â€œfront end developerâ€ â†’ â€œfrontend developerâ€
- â€œback end developerâ€ â†’ â€œbackend developerâ€
- â€œfull stack engineerâ€ â†’ â€œfullstack engineerâ€

### **C) Semantic Standardization**
- â€œdeveloperâ€ â†’ â€œsoftware developerâ€
- â€œscientistâ€ â†’ â€œresearch scientistâ€
- â€œit project managerâ€ â†’ â€œproject managerâ€

Unique job titles reduced from **125 â†’ 118**, improving dataset consistency significantly.

---

## 5. Education Level Mapping

Mapped into four unified categories:

high_school, bachelor, master, phd


Missing values were filled as `"unknown"`.

---

## 6. Numeric Cleaning and Type Conversion

`age`, `years_experience`, and `salary` were converted to numeric using coercion.  
Invalid values became NaN and were imputed using the **median**.

---

## 7. Logical Filters and Outlier Removal

We applied domain-specific constraints:

- Age must be between 18â€“70  
- Years of experience must be 0â€“50  
- Salary must be greater than 0  
- Top 1% salary outliers removed (210k â†’ 200k)

This improves model robustness by preventing extreme values from skewing distributions.

---

## 8. Handling Missing Data

- Rows missing salary were removed  
- Categorical missing values â†’ â€œunknownâ€  
- Numeric missing values â†’ median  

This preserves data volume while ensuring statistical stability.

---

## 9. Dataset Merging and Duplicate Removal

The two datasets were concatenated, then duplicates removed using:

age, job_title, education_level, years_experience, salary, seniority_level


Results:

- Before cleaning: **9991 duplicates**
- After cleaning: **0 duplicates**

This ensures each observation represents a unique sample.

---

## 10. Final Dataset and Quality Summary

The cleaned dataset was saved to:

data/processed/main_salary_dataset.csv


---

# ğŸ“Š Data Quality and Feature Diversity Summary

### age  
- Unique: 41  
- Mean: 35.27  
- Range: 21â€“62  

### job_title  
- Unique: 118  
- Representative titles:  
  backend developer, customer service representative, data scientist, software engineer, fullstack engineer  

### education_level  
bachelor, high_school, master, phd, unknown  

### years_experience  
- Unique: 37  
- Mean: 9.24  

### salary  
- Unique: 437  
- Mean: 112,905  
- Median: 110,000  
- Max (cleaned): 200,000  

### seniority_level  
junior, senior  

---

## ğŸ“ Revision Notes

After reviewing the Data Quality Report, additional normalization and typo correction were applied to job_title values. The dataset was regenerated to reflect these improvements, ensuring maximum consistency and modeling readiness.

